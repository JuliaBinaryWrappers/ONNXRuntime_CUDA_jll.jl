# `ONNXRuntime_CUDA_jll.jl` (v1.10.0+0)

[![deps](https://juliahub.com/docs/ONNXRuntime_CUDA_jll/deps.svg)](https://juliahub.com/ui/Packages/General/ONNXRuntime_CUDA_jll/)

This is an autogenerated package constructed using [`BinaryBuilder.jl`](https://github.com/JuliaPackaging/BinaryBuilder.jl).

The originating [`build_tarballs.jl`](https://github.com/JuliaPackaging/Yggdrasil/blob/081828fac9f8abe89a4816628ce647b34fbbfa55/O/ONNXRuntime/ONNXRuntime_CUDA/build_tarballs.jl) script can be found on [`Yggdrasil`](https://github.com/JuliaPackaging/Yggdrasil/), the community build tree.

## Bug Reports

If you have any issue, please report it to the Yggdrasil [bug tracker](https://github.com/JuliaPackaging/Yggdrasil/issues).

## Documentation

For more details about JLL packages and how to use them, see `BinaryBuilder.jl` [documentation](https://docs.binarybuilder.org/stable/jll/).

## Sources

The tarballs for `ONNXRuntime_CUDA_jll.jl` have been built from these sources:

* git repository: https://github.com/microsoft/onnxruntime.git (revision: `0d9030e79888d1d5828730b254fedc53c7b640c1`)
* compressed archive: https://github.com/microsoft/onnxruntime/releases/download/v1.10.0/onnxruntime-win-x64-gpu-1.10.0.zip (SHA256 checksum: `0da11b8d953fad4ec75f87bb894f72dea511a3940cff2f4dad37451586d1ebbc`)
* file: https://nvidia.box.com/shared/static/jy7nqva7l88mq9i8bw3g3sklzf4kccn2.whl (SHA256 checksum: `a608b7a4a4fc6ad5c90d6005edbfe0851847b991b08aafff4549bbbbdb938bf6`)

## Platforms

`ONNXRuntime_CUDA_jll.jl` is available for the following platforms:

* `Windows x86_64 {cuda=11.3}` (`x86_64-w64-mingw32-cuda+11.3`)

## Dependencies

The following JLL packages are required by `ONNXRuntime_CUDA_jll.jl`:

* [`CUDA_Runtime_jll`](https://github.com/JuliaBinaryWrappers/CUDA_Runtime_jll.jl)
* [`CUDNN_jll`](https://github.com/JuliaBinaryWrappers/CUDNN_jll.jl)
* [`TensorRT_jll`](https://github.com/JuliaBinaryWrappers/TensorRT_jll.jl)
* [`Zlib_jll`](https://github.com/JuliaBinaryWrappers/Zlib_jll.jl)

## Products

The code bindings within this package are autogenerated from the following `Products`:

* `LibraryProduct`: `libonnxruntime`
* `LibraryProduct`: `libonnxruntime_providers_cuda`
* `LibraryProduct`: `libonnxruntime_providers_shared`
* `LibraryProduct`: `libonnxruntime_providers_tensorrt`
